{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using scikit-learn [`TfIdfVectortizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download newsgroups dataset\n",
    "Remove headers, footers and quotes to only train on the content of the post (instead of overfitting on headers etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories,\n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                      categories=categories,\n",
    "                                      remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news: 2034\n",
      "\n",
      "Number of targets: 4\n",
      "\n",
      "Target names: alt.atheism, comp.graphics, sci.space, talk.religion.misc\n",
      "\n",
      "Sample news: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "'Sample targets: [1 3 2 0 2 0 2 1 2 1]'\n"
     ]
    }
   ],
   "source": [
    "print('Number of news: %d\\n' % len(newsgroups_train.data))\n",
    "print('Number of targets: %d\\n' % len(newsgroups_train.target_names))\n",
    "print('Target names: %s\\n' % ', '.join(newsgroups_train.target_names))\n",
    "print('Sample news: %s\\n' % newsgroups_train.data[0])\n",
    "pprint('Sample targets: %s' % newsgroups_train.target[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2034, 26879)\n",
      "Dimensionality of vocabulary: 26879\n",
      "Size of vocabulary: 26879\n",
      "Non-zero values: 196700/54671886 (0.36 %)\n",
      "Average non-zero values per document: 96.7\n",
      "Sample values:   (0, 4030)\t0.0662337497043734\n",
      "  (0, 5604)\t0.1373223718234628\n",
      "  (0, 2408)\t0.0697108745652997\n",
      "  (0, 4326)\t0.030618868877639698\n",
      "  (0, 2427)\t0.03931807830514708\n",
      "  (0, 9935)\t0.10024033927265849\n",
      "  (0, 3397)\t0.10759772335500424\n",
      "  (0, 8620)\t0.09565891146117879\n",
      "  (0, 5220)\t0.03282557123888892\n",
      "  (0, 3254)\t0.024133239174785947\n",
      "  (0, 7761)\t0.10778332049617564\n",
      "  (0, 3607)\t0.0653195128299407\n",
      "  (0, 2853)\t0.05796490248169242\n",
      "  (0, 1152)\t0.3399039986832978\n",
      "  (0, 5443)\t0.10024033927265849\n",
      "  (0, 3042)\t0.039840864696320574\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "vectors = tfidf_vectorizer.fit_transform(newsgroups_train.data)\n",
    "print('Shape: ', vectors.shape)\n",
    "print('Dimensionality of vocabulary: %d' % vectors.shape[1])\n",
    "print('Size of vocabulary: %d' % len(tfidf_vectorizer.vocabulary_.keys()))\n",
    "nnz = vectors.nnz\n",
    "n = vectors.shape[0] * vectors.shape[1]\n",
    "print('Non-zero values: %d/%d (%.2f %%)' % (vectors.nnz, n, vectors.nnz / n * 100))\n",
    "print('Average non-zero values per document: %.1f' % (vectors.nnz / vectors.shape[0]))\n",
    "print('Sample values:', vectors[0, :10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2034, 26879)\n",
      "Dimensionality of vocabulary: 26879\n",
      "Size of vocabulary: 26879\n",
      "Sample values   (0, 3042)\t1\n",
      "  (0, 5443)\t1\n",
      "  (0, 1152)\t3\n",
      "  (0, 2853)\t1\n",
      "  (0, 3607)\t2\n",
      "  (0, 7761)\t1\n",
      "  (0, 3254)\t1\n",
      "  (0, 5220)\t1\n",
      "  (0, 8620)\t2\n",
      "  (0, 3397)\t2\n",
      "  (0, 9935)\t1\n",
      "  (0, 2427)\t1\n",
      "  (0, 4326)\t1\n",
      "  (0, 2408)\t1\n",
      "  (0, 5604)\t1\n",
      "  (0, 4030)\t1\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "vectors_count = count_vectorizer.fit_transform(newsgroups_train.data)\n",
    "print('Shape: ', vectors_count.shape)\n",
    "print('Dimensionality of vocabulary: %d' % vectors_count.shape[1])\n",
    "print('Size of vocabulary: %d' % len(count_vectorizer.vocabulary_.keys()))\n",
    "print('Sample values', vectors_count[0, :10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('vectorize',\n",
       "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                                  decode_error='strict',\n",
       "                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                  encoding='utf-8',\n",
       "                                                  input='content',\n",
       "                                                  lowercase=True, max_df=1.0,\n",
       "                                                  max_features=None, min_df=1,\n",
       "                                                  ngram_range=(1, 1), norm='l2',\n",
       "                                                  preprocessor=None,\n",
       "                                                  smooth_idf=True,\n",
       "                                                  stop_words=None,\n",
       "                                                  strip_accents=None,\n",
       "                                                  sublinear_tf=False,\n",
       "                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                  tokenizer=None, use_idf=True,\n",
       "                                                  vocabulary=None))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing = Pipeline(steps=[('vectorize', TfidfVectorizer())])\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "pipeline = Pipeline(steps=[('preprocessing', preprocessing), ('clf', classifier)])\n",
    "pipeline.fit(newsgroups_train.data, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro score: 0.79\n"
     ]
    }
   ],
   "source": [
    "pred = pipeline.predict(newsgroups_test.data)\n",
    "print('F1 micro score: %.2f' % metrics.f1_score(newsgroups_test.target, pred, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml-3.6.2",
   "language": "python",
   "name": "python-ml-3.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
