{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Ch. 3 example of \"Deep Learning with Python\" by F. Chollet\n",
    "# Adds k-fold validation and sklearn StandardScaler to the example\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "# Shuffle for kicks\n",
    "train_data, train_targets = shuffle(train_data, train_targets, random_state = 0)\n",
    "test_data, test_targets = shuffle(test_data, test_targets, random_state = 0)\n",
    "\n",
    "# Targets to 2D arrays\n",
    "train_targets = np.reshape(train_targets, (train_targets.shape[0], 1))\n",
    "test_targets = np.reshape(test_targets, (test_targets.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_features = StandardScaler()\n",
    "X_train = sc_features.fit_transform(train_data)\n",
    "X_test = sc_features.transform(test_data)\n",
    "\n",
    "# Scaling for targets, skipped now\n",
    "# sc_labels = StandardScaler()\n",
    "# sc_labels = sc_labels.fit(np.reshape(train_targets, (train_targets.shape[0], 1)))\n",
    "# Y_train = sc_labels.transform(train_targets)\n",
    "# Y_test = sc_labels.transform(test_targets)\n",
    "\n",
    "Y_train = train_targets\n",
    "Y_test = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape = (train_data.shape[1], )))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1)) # 1D regression\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "def train_for(X_train, Y_train, X_validation, Y_validation, epochs = 250):\n",
    "    model = build_model()\n",
    "    history = model.fit(X_train, Y_train, epochs = epochs, verbose = 0, validation_data = (X_validation, Y_validation))\n",
    "    return model, history\n",
    "\n",
    "def k_fold_validate(folds):\n",
    "    kf = KFold(n_splits=folds)\n",
    "    split_indices = kf.split(X_train)\n",
    "    histories = []\n",
    "    for train_index, test_index in split_indices:\n",
    "        X_train_split = X_train[train_index]\n",
    "        Y_train_split = Y_train[train_index]\n",
    "        X_test_split = X_train[test_index]\n",
    "        Y_test_split = Y_train[test_index]\n",
    "        model, history = train_for(X_train_split, Y_train_split, X_test_split, Y_test_split)\n",
    "        histories.append(history)\n",
    "    return histories\n",
    "    \n",
    "histories = k_fold_validate(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation mean absolute errors vs. training epoch\n",
    "\n",
    "def average_for_quantity(histories, quantity):\n",
    "    vals = [history.history[quantity] for history in histories]\n",
    "    return np.mean(vals, axis = 0)\n",
    "\n",
    "# train_losses = average_for_quantity(histories, 'loss')\n",
    "# val_losses = average_for_quantity(histories, 'val_loss')\n",
    "\n",
    "train_maes = average_for_quantity(histories, 'mean_absolute_error')\n",
    "val_maes = average_for_quantity(histories, 'val_mean_absolute_error')\n",
    "\n",
    "arg_val_min = np.argmin(val_maes)\n",
    "\n",
    "epochs = range(0, len(train_maes))\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_maes, 'b-', label='Training mean absolute error')\n",
    "plt.plot(epochs, val_maes, 'r-', label='Validation mean absolute error')\n",
    "plt.plot([arg_val_min, arg_val_min], [0, np.amax(val_maes)], 'g--', label = 'Validation minimum')\n",
    "plt.title('Training and validation loss, min validation %.2f' % (val_maes[arg_val_min]))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.xlim([10, len(epochs)])\n",
    "plt.ylim([0, max(val_maes[10:])])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model once more with all data and optimal number of epochs, without validation data\n",
    "model, history = train_for(X_train, Y_train, np.zeros((0, X_train.shape[1])), np.zeros((0, Y_train.shape[1])), \n",
    "                           epochs = arg_val_min + 1)\n",
    "\n",
    "evaluated = model.evaluate(X_test, Y_test)\n",
    "\n",
    "# Dictionary of computed losses and metrics\n",
    "test_results = dict(zip(model.metrics_names, evaluated))\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example utilizing EarlyStopping callback when validation losses stop improving\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlyStop = EarlyStopping(monitor = 'val_mean_absolute_error', min_delta = 0, patience = 5, verbose = 1, mode = 'auto')\n",
    "\n",
    "def train_with_early_stop(X_train, Y_train, X_validation, Y_validation, epochs = 250):\n",
    "    model = build_model()\n",
    "    history = model.fit(X_train, Y_train, epochs = epochs, verbose = 0, validation_data = (X_validation, Y_validation), \n",
    "                       callbacks = [earlyStop])\n",
    "    return model\n",
    "\n",
    "def k_fold_validate_early_stop(folds):\n",
    "    kf = KFold(n_splits=folds)\n",
    "    split_indices = kf.split(X_train)\n",
    "    metrics = []\n",
    "    for train_index, test_index in split_indices:\n",
    "        X_train_split = X_train[train_index]\n",
    "        Y_train_split = Y_train[train_index]\n",
    "        X_test_split = X_train[test_index]\n",
    "        Y_test_split = Y_train[test_index]\n",
    "        model = train_with_early_stop(X_train_split, Y_train_split, X_test_split, Y_test_split)\n",
    "        evaluated = model.evaluate(X_test_split, Y_test_split)\n",
    "        metrics.append(dict(zip(model.metrics_names, evaluated)))\n",
    "    return np.mean([metrics_for_fold['mean_absolute_error'] for metrics_for_fold in metrics])\n",
    "\n",
    "mean_absolute_error = k_fold_validate_early_stop(folds = 5)\n",
    "print('Mean absolute error: %.2f' % (mean_absolute_error))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
