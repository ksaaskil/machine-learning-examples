{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to convolutional networks\n",
    "### Based on Chapter 5 from \"Deep Learning with Python\" by F. Chollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example to get started\n",
    "- Load data (import bundled with Keras)\n",
    "- Reshape images and scale 8-bit pixel values between zero and one\n",
    "- Categorically encode labels, for example: \"2\" -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "def prepare_images(images):\n",
    "    return images.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
    "\n",
    "# Reshape images and scale between zero and one\n",
    "train_images = prepare_images(train_images)\n",
    "test_images = prepare_images(test_images)\n",
    "\n",
    "# Categorical encoding of class labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define convolutional network and add dense network on top as classifier. \n",
    "In the convolutional network, patterns are learned from windows of size 3x3. First convolution layer outputs feature maps of size (26, 26, 32). In the first two dimensions, size has decreased from 28 to 26 because of border effects: without padding, there are only 26 pixel positions where 3x3 windows can be placed along an axis with 28 pixels. The size of the output feature map in the third dimension, set to 32 in the first convolution layer and 64 in the following two, is a configurable parameter corresponding to different \"filters\", analogous to color channels in RGB image.\n",
    "\n",
    "_MaxPooling_ layers are used to downsample the feature maps. Max pooling selects the maximum value from windows of size 2x2. Downsampling not only reduces the number of trainable coefficients but also spreads information: the convolution layer following a MaxPooling layer works on 3x3 windows containing information from larger area of the original image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional network\n",
    "\n",
    "# In the first layers, learn patterns from 3x3 windows\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network and evaluate performance on test-set\n",
    "This step contains no cross-validation and basically only ensures that things are properly set-up. Accuracy on the test set exceeds 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, epochs = 5, batch_size = 64)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy %.4f' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some of the failed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = to_categorical(model.predict_classes(test_images))\n",
    "\n",
    "# Indices of failed predictions, there might be simpler way to do this\n",
    "import numpy as np\n",
    "failures = np.nonzero(np.sum(np.abs(predicted_labels - test_labels), axis = 1))[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_for_ind(ind):\n",
    "    img_failed = test_images[ind_failed]\n",
    "\n",
    "    predicted_label = np.nonzero(predicted_labels[ind_failed])[0][0]\n",
    "    labeled = np.nonzero(test_labels[ind_failed])[0][0]\n",
    "\n",
    "    plt.imshow(np.reshape(img_failed, (28, 28)), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "    plt.title('Predicted %d, labeled %d' % (predicted_label, labeled))\n",
    "    plt.show()\n",
    "\n",
    "# Visualize five of failed predictions\n",
    "for ind_failed in failures[0:5]:\n",
    "    plot_for_ind(ind_failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs. Dogs\n",
    "- Requires loading data from [Kaggle dogs vs. cats](https://www.kaggle.com/c/dogs-vs-cats/data) and moving to `./datasets/dogs-vs-cats-original/`\n",
    "- Script below splits fraction of data to training, validation and test sets, with dogs and cats in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_data_set_dir = './datasets/dogs-vs-cats-original'\n",
    "target_base_dir = './datasets/dogs-vs-cats'\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    print(\"Creating %s if not exist\" % directory)\n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "\n",
    "ensure_dir(target_base_dir)\n",
    "\n",
    "train_dir = os.path.join(target_base_dir, 'train')\n",
    "validation_dir = os.path.join(target_base_dir, 'validation')\n",
    "test_dir = os.path.join(target_base_dir, 'test')\n",
    "\n",
    "for directory in [train_dir, validation_dir, test_dir]:\n",
    "    ensure_dir(directory)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "def copy_files(filenames, src_dir, dst_dir):\n",
    "    ensure_dir(dst_dir)\n",
    "    print('Copying %d files from %s to %s' % (len(filenames), src_dir, dst_dir))\n",
    "    for fname in filenames:\n",
    "        shutil.copyfile(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
    "        \n",
    "training_ids = [i for i in range(1000)]\n",
    "validation_ids = [i for i in range(1000, 1500)]\n",
    "test_ids = [i for i in range(1500, 2000)]\n",
    "\n",
    "copy_files(filenames = ['cat.{}.jpg'.format(i) for i in training_ids], \n",
    "           src_dir = original_data_set_dir, \n",
    "           dst_dir = train_cats_dir)\n",
    "\n",
    "copy_files(filenames = ['dog.{}.jpg'.format(i) for i in training_ids], \n",
    "           src_dir = original_data_set_dir, \n",
    "           dst_dir = train_dogs_dir)\n",
    "\n",
    "copy_files(filenames = ['cat.{}.jpg'.format(i) for i in validation_ids], \n",
    "           src_dir = original_data_set_dir, \n",
    "           dst_dir = validation_cats_dir)\n",
    "\n",
    "copy_files(filenames = ['dog.{}.jpg'.format(i) for i in validation_ids], \n",
    "           src_dir = original_data_set_dir, \n",
    "           dst_dir = validation_dogs_dir)\n",
    "\n",
    "copy_files(filenames = ['cat.{}.jpg'.format(i) for i in test_ids], \n",
    "           src_dir = original_data_set_dir, \n",
    "           dst_dir = test_cats_dir)\n",
    "\n",
    "copy_files(filenames = ['dog.{}.jpg'.format(i) for i in test_ids], \n",
    "           src_dir = original_data_set_dir, \n",
    "           dst_dir = test_dogs_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define [ImageDataGenerator](https://keras.io/preprocessing/image/#imagedatagenerator-class) for reading images to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "gen_batch_size = 20\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = gen_batch_size,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = gen_batch_size,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "# Demonstrate the generator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loop_counter = 0\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data batch shape:', data_batch.shape)\n",
    "    print('Label batch shape:', labels_batch.shape)\n",
    "    plt.imshow(data_batch[0])\n",
    "    plt.title('Dog' if int(labels_batch[0]) == 1 else 'Cat')\n",
    "    plt.show()\n",
    "    loop_counter += 1\n",
    "    if loop_counter > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define convolution network\n",
    "Network consists of four convolution layers (each with max pooling) and a final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(lr = 1e-4), metrics = ['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Note that generator does not know how many batches makes one epoch, so one needs to define `steps_per_epoch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = len(training_ids) / gen_batch_size,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = len(validation_ids) / gen_batch_size)\n",
    "\n",
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'rs-', label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
