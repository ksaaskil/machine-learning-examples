{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of time-series forecasting\n",
    "### Based on Chap 6.3. from [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by F. Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Jena climate data set as Pandas dataframe\n",
    "Fetch the CSV using `fetch_jena_climate.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_file = './datasets/jena_climate/jena_climate_2009_2016.csv'\n",
    "\n",
    "data = pd.read_csv(csv_file)\n",
    "data['Date Time'] = pd.to_datetime(data['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data_sample = data.head(250)\n",
    "\n",
    "def plot_column(column):\n",
    "    fig = plt.figure(figsize = (15, 4))\n",
    "    plt.plot(data_sample['Date Time'], data_sample[column])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(column)\n",
    "    \n",
    "plot_column('T (degC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to NumPy data, dropping the date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_without_timestamp = data.drop(['Date Time'], axis=1)\n",
    "float_data = np.array(data_without_timestamp, dtype=np.float32)[:, 1:]\n",
    "\n",
    "training_inds = range(20000)\n",
    "validation_inds = range(training_inds[-1] + 1, 30000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(float_data[training_inds])\n",
    "float_data = scaler.transform(float_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator for reading input batches from the multi-dimensional timeseries\n",
    "- `step`: The step at which data is sampled for prediction (orig. data sampled every 10 minutes, so use `step=6` for one-hour time step)\n",
    "- `lookback`: How many steps to look into the past to predict the future (in units of 10 min). Each input has `lookback // step` time series points.\n",
    "- `delay`: How many timesteps to the future to predict (in units of 10 min)\n",
    "- `min_index` and `max_index`: Indices used for keeping training and validation data separate\n",
    "- `shuffle`: Should the rows be picked randomly or in chronological order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index, shuffle = False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            batch_rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            batch_rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(batch_rows)\n",
    "        samples = np.zeros((len(batch_rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(batch_rows),))\n",
    "        for j, row in enumerate(batch_rows):\n",
    "            indices = range(batch_rows[j] - lookback, batch_rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[batch_rows[j] + delay][1]\n",
    "        yield samples, targets\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 6 # Training samples sampled every one hour\n",
    "lookback = 3 * 24 * 6 # Use data from 3 previous days for prediction (input data sampled every 10 minutes)\n",
    "delay = 24 * 6 # Trying to predict temperature one day to the future\n",
    "batch_size = 128\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "partial_gen = partial(generator, \n",
    "                      data = float_data, \n",
    "                      lookback = lookback, \n",
    "                      delay = delay, \n",
    "                      batch_size = batch_size)\n",
    "\n",
    "train_gen = partial_gen(min_index = 0, \n",
    "                        max_index = training_inds[-1], \n",
    "                        shuffle = True)\n",
    "\n",
    "val_gen = partial_gen(min_index = validation_inds[0], max_index = validation_inds[-1])\n",
    "\n",
    "test_gen = partial_gen(min_index = validation_inds[-1], max_index = None)\n",
    "\n",
    "val_steps = validation_inds[-1] - validation_inds[0] - lookback\n",
    "test_steps = len(float_data) - validation_inds[-1] - lookback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-forward fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Flatten(input_shape = (lookback // step, float_data.shape[-1])))\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer = RMSprop(), loss = 'mae')\n",
    "history = model.fit_generator(train_gen, \n",
    "                              steps_per_epoch = 500, \n",
    "                              epochs = 5, \n",
    "                              validation_data = val_gen, \n",
    "                              validation_steps = val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape = (None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer = RMSprop(), loss = 'mae')\n",
    "history = model.fit_generator(train_gen, \n",
    "                              steps_per_epoch = 500, \n",
    "                              epochs = 20, \n",
    "                              validation_data = val_gen, \n",
    "                              validation_steps = val_steps)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
