{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example of 1D linear regression with Keras\n",
    "To demonstrate the basic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features and targets (\"X\" and \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "hidden_slope = 5.0\n",
    "hidden_bias = 5.0\n",
    "\n",
    "hidden_model = lambda x: hidden_slope * x + hidden_bias\n",
    "\n",
    "samples = 100\n",
    "\n",
    "X = np.linspace(1, 10, samples)\n",
    "X = np.reshape(X, (-1, 1))\n",
    "\n",
    "Y_noise_std = 10\n",
    "\n",
    "Y = hidden_model(X) + np.random.randn(X.shape[0], X.shape[1]) * Y_noise_std\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y, random_state = 42)\n",
    "\n",
    "print('X shape: (%d, %d)' % X.shape)\n",
    "print('Y shape: (%d, %d)' % Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(X, Y, 'bo')\n",
    "plt.plot(X, hidden_model(X), 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data to training and validation sets and preprocess using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "\n",
    "Y_scaler = StandardScaler()\n",
    "Y_train = Y_scaler.fit_transform(Y_train)\n",
    "\n",
    "plt.plot(X_train, Y_train, 'bo')\n",
    "plt.plot(X_scaler.transform(X), Y_scaler.transform(hidden_model(X)), 'r--')\n",
    "plt.xlabel('X scaled')\n",
    "plt.ylabel('Y scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Keras model with one layer containing one node with linear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.activations import linear\n",
    "model.add(Dense(1, activation=linear, input_dim = 1))\n",
    "\n",
    "from keras import optimizers\n",
    "optimizer = optimizers.SGD(lr = 0.05)\n",
    "\n",
    "from keras import losses\n",
    "loss = losses.mean_squared_error\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = ['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model, plot training and validation loss vs. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 50, verbose = 1, validation_split=0.20)\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "epochs = len(history_dict['loss'])\n",
    "\n",
    "plt.plot(range(1, epochs + 1), history_dict['loss'], 'bo-', label = 'Training loss')\n",
    "plt.plot(range(1, epochs + 1), history_dict['val_loss'], 'rs--', label = 'Validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict targets for test set, plot and compare to model noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(fitted_model):\n",
    "    Y_predicted = Y_scaler.inverse_transform(fitted_model.predict(X_scaler.transform(X_test)))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_test, Y_test, 'bo', label = 'Test set')\n",
    "    plt.plot(X_test, Y_predicted, 'ro', label = 'Predicted')\n",
    "    plt.plot(X, hidden_model(X), 'k--', label = 'Hidden model')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_scaler.inverse_transform(X_train), Y_scaler.inverse_transform(Y_train), 'ko', label = 'Training set')\n",
    "    plt.plot(X_scaler.inverse_transform(X_train), Y_scaler.inverse_transform(fitted_model.predict(X_train)), 'go', label = 'Training set predicted')\n",
    "    plt.plot(X, hidden_model(X), 'k--', label = 'Hidden model')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_predictions(model)\n",
    "\n",
    "Y_predicted = Y_scaler.inverse_transform(model.predict(X_scaler.transform(X_test)))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('RMS error %.1f (noise %.1f)' % (np.sqrt(mean_squared_error(Y_test, Y_predicted)), Y_noise_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with [KerasRegressor](https://keras.io/scikit-learn-api/) scikit-learn integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def build_model(hidden_layers = 0, units = 3, lr = 0.05):\n",
    "    # print('Creating model with learning rate %.3f, %d hidden layers (%d units)' % (lr, hidden_layers, units))\n",
    "    from keras.models import Sequential\n",
    "    model = Sequential()\n",
    "\n",
    "    from keras.layers import Dense\n",
    "    from keras.activations import linear, relu\n",
    "    \n",
    "    has_first_layer = False\n",
    "    \n",
    "    for i in range(0, hidden_layers):\n",
    "        if not has_first_layer:\n",
    "            model.add(Dense(units=units, activation=relu, input_dim=1))\n",
    "            has_first_layer = True\n",
    "        else:\n",
    "            model.add(Dense(units = units, activation=relu))\n",
    "            \n",
    "    if has_first_layer:\n",
    "        model.add(Dense(units = 1, activation=linear))\n",
    "    else:\n",
    "        model.add(Dense(units = 1, activation=linear, input_dim=1))\n",
    "\n",
    "    from keras import optimizers\n",
    "    optimizer = optimizers.SGD(lr)\n",
    "\n",
    "    from keras import losses\n",
    "    loss = losses.mean_squared_error\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = ['mse'])\n",
    "    # print(model.summary())\n",
    "    return model\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = np.expand_dims(y_pred, 1) # Required as regressor predictions are 1D arrays\n",
    "    assert y_pred.shape[0] == y_true.shape[0]\n",
    "    assert y_pred.shape[1] == y_true.shape[1]\n",
    "    assert y_pred.ndim == y_true.ndim\n",
    "    scaled_diff = Y_scaler.inverse_transform(y_true) - Y_scaler.inverse_transform(y_pred)\n",
    "    return np.sqrt(np.mean(scaled_diff * scaled_diff))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better = False)\n",
    "\n",
    "regressor = KerasRegressor(build_fn=build_model, epochs = 50, lr = 0.05, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of fitting the KerasRegressor, note that parameters are tunable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, Y_train, epochs = 50)\n",
    "\n",
    "plot_predictions(regressor)\n",
    "\n",
    "Y_predicted = Y_scaler.inverse_transform(np.expand_dims(regressor.predict(X_scaler.transform(X_test)), 1))\n",
    "rmse_mean = rmse(Y_scaler.transform(Y_predicted), Y_scaler.transform(Y_test))\n",
    "\n",
    "print('RMS error %.1f (noise %.1f)' % (rmse_mean, Y_noise_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of cross-validation with scikit-learn\n",
    "Uses the default parameters given for regressor above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(regressor, \n",
    "                        X_train, \n",
    "                        Y_train, \n",
    "                        scoring = { \n",
    "                            'rmse': rmse_scorer\n",
    "                        },\n",
    "                        cv = 5, \n",
    "                        verbose = 1)\n",
    "\n",
    "print('Mean CV RMSE error: %.2f' % np.mean(scores['test_rmse']))\n",
    "import pandas as pd\n",
    "cv_scores = pd.DataFrame.from_dict(scores)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search example\n",
    "Both model parameters and fitting parameters can be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "    'epochs': [25, 50],\n",
    "    'lr': [0.01],\n",
    "    'hidden_layers': [0, 1, 2],\n",
    "    'units': [3]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(regressor,\n",
    "                           param_grid, \n",
    "                           cv = 5, \n",
    "                           scoring = { \n",
    "                             'rmse': rmse_scorer\n",
    "                           },\n",
    "                          verbose = 2,\n",
    "                          refit = 'rmse'\n",
    "                          )\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print('Best params: %s, best score: %.2f' % (grid_search.best_params_, grid_search.best_score_))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame.from_dict(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(grid_search.best_estimator_)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "Y_predicted = Y_scaler.inverse_transform(grid_search.best_estimator_.predict(X_scaler.transform(X_test)))\n",
    "print('RMS error %.1f (noise %.1f)' % (np.sqrt(mean_squared_error(Y_test, Y_predicted)), Y_noise_std))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
