{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification examples based on Chapter 4 of \"Hands-on Machine Learning with scikit-learn and TensorFlow\" by Aurélien Géron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MNIST data using TensorFlow as it's easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training and test data and shuffle training set just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "print('Shape of X: (%d, %d)' % X.shape)\n",
    "print('Shape of y: (%d, %d)' % y.shape)\n",
    "\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit_index = [index for index, label in enumerate(y_train) if label == 5][0]\n",
    "digit = X_train[digit_index]\n",
    "digit_image = digit.reshape(28, 28)\n",
    "\n",
    "digit_label = y_train[digit_index]\n",
    "\n",
    "plt.imshow(digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.title('Labelled as %d' % digit_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "### Do binary classification trying to classify images as \"5 or \"not a 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a simple `SGDClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(loss='log', random_state=42, max_iter=1000, tol=1e-3)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.predict([digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance with 5-fold cross validation using accuracy as scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cv_scores = cross_val_score(sgd_clf, X_train, y_train_5, cv=5, scoring=\"accuracy\")\n",
    "print('Got mean accuracy %.2f with std of %.2f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to silly \"not 5\" estimator that also gets 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((X.shape[0], 1), dtype=bool)\n",
    "never_5_clf = Never5Classifier()\n",
    "cv_scores_2 = cross_val_score(never_5_clf, X_train, y_train_5, cv=5, scoring=\"accuracy\")\n",
    "print('Got mean accuracy %.2f with std of %.2f' % (np.mean(cv_scores_2), np.std(cv_scores_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that accuracy is not that good a metric for a skewed dataset with lots of \"not 5\":s, so let's look at confusion matrix instead. First compute predictions for all images in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then compute the confusion matrix. The values go like this:\n",
    "<table>\n",
    "  <tr>\n",
    "     <th>true negatives for not 5</th>\n",
    "     <th>false positives for not 5</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "     <th>false negatives for a 5</th>\n",
    "     <th>true positives for a 5</th> \n",
    "  </tr>\n",
    "</table>\n",
    "or generally for binary classifier\n",
    "<table>\n",
    "  <tr>\n",
    "     <th>Class 0 predicted as 0</th>\n",
    "     <th>Class 0 predicted as 1</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "     <th>Class 1 predicted as 0</th>\n",
    "     <th>Class 1 predicted as 1</th> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_train_5, y_train_pred)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute precision and recall defined as \n",
    "$$ precision = \\frac{TP}{TP + FP} $$\n",
    "and \n",
    "$$ recall = \\frac{TP}{TP + FN} $$\n",
    "- Precision depicts the probability that an image predicted to be a five actually was a five.\n",
    "- Recall is the probability that an image labelled as five was correctly predicted to be a five.\n",
    "\n",
    "The harmonic mean of precision and recall is the $F_1$ score:\n",
    "$$ F_1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def print_metrics(y_train, y_pred):\n",
    "    print('Got precision %.2f' % (precision_score(y_train, y_pred)))\n",
    "    print('Got recall %.2f' % (recall_score(y_train, y_pred)))\n",
    "    print('Got F1 score %.2f' % (f1_score(y_train, y_pred)))\n",
    "print_metrics(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One can tune the precision-recall tradeoff by tuning the decision boundary threshold. While this cannot be set for `SGDClassifier` directly, one can access the decision function and classify using a threshold. Increasing the threshold increases precision, as classifier classifies less images as fives. It reduces the recall, as more fives are missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDClassifierWithThreshold(BaseEstimator):\n",
    "    def __init__(self, sgd_clf, threshold):\n",
    "        self.threshold = threshold\n",
    "        self.sgd_clf = sgd_clf\n",
    "        # super().__init__()\n",
    "    def fit(self, X, y=None):\n",
    "        self.sgd_clf.fit(X, y)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return self.sgd_clf.decision_function(X) > self.threshold\n",
    "\n",
    "X_fives = X_train[y_train_5]\n",
    "X_not_fives = X_train[~y_train_5]\n",
    "\n",
    "sgd_with_threshold = SGDClassifierWithThreshold(sgd_clf=SGDClassifier(max_iter=1000, tol=1e-3), threshold=3)\n",
    "y_train_pred = cross_val_predict(sgd_with_threshold, X_train, y_train_5, cv=5)\n",
    "print_metrics(y_train_5, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One can plot the precision-recall curve straightforwardly by computing the decision function values for all training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=5, method='decision_function')\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlim([-10, 10])\n",
    "    \n",
    "plot_precision_recall_threshold(precisions, recalls, thresholds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
